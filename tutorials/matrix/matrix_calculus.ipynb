{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "912d027e-a47e-406b-af75-49273d70987e",
   "metadata": {},
   "source": [
    "- references\n",
    "    - https://atmos.washington.edu/~dennis/MatrixCalculus.pdf\n",
    "    - https://math.stackexchange.com/questions/312077/differentiate-fx-xtax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a28e667-88fa-4e41-ba10-0caa0859a5db",
   "metadata": {},
   "source": [
    "## cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e28754-1036-4bae-a93a-1f1668bbe3dd",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{split}\n",
    "&\\frac{\\partial}{\\partial x}(v^Tx)=v\\\\\n",
    "&\\frac{\\partial}{\\partial x}(A\\cdot x)=A\\\\\n",
    "&\\frac{\\partial}{\\partial x}(x^TAx)=2Ax\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65850e36-1eae-4352-939a-ca651282bde4",
   "metadata": {},
   "source": [
    "## $\\mathbf y=\\mathbf {Ax}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d924ef-2549-4345-b659-f56167cd246e",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{y} = \\psi(\\mathbf{x}),\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{x}} = \n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial y_1}{\\partial x_1} & \\frac{\\partial y_1}{\\partial x_2} & \\cdots & \\frac{\\partial y_1}{\\partial x_n} \\\\\n",
    "\\frac{\\partial y_2}{\\partial x_1} & \\frac{\\partial y_2}{\\partial x_2} & \\cdots & \\frac{\\partial y_2}{\\partial x_n} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial y_m}{\\partial x_1} & \\frac{\\partial y_m}{\\partial x_2} & \\cdots & \\frac{\\partial y_m}{\\partial x_n}\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "- $\\mathbf{y} = \\psi(\\mathbf{x}),$ 比如 $\\mathbf y=\\mathbf {Ax}$\n",
    "- $\\frac{\\partial \\mathbf y}{\\partial \\mathbf x}$ 向量（多元输出，multi-variables）对向量（多元输入，multi-inputs）的导数，此时的输出是 jacobian matrix\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "&\\mathbf y=\\mathbf {Ax}\\\\\n",
    "&\\frac{\\partial \\mathbf y}{\\partial \\mathbf x}=\\mathbf A\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "- 我们来进行简单的推导\n",
    "    - $y_i=A_{[i]}x=\\sum_k a_{ik}x_k$\n",
    "        - $y_1=\\sum_ka_{1k}x_k$\n",
    "- 一个特例，当 $A$ 为一个行向量时（$\\mathbf w^T$），退化为一个多元输入，单输出（标量 scalar 输出）的内积运算，此时的导数为与输入等shape的向量；\n",
    "\n",
    "    $$\n",
    "    y=\\mathbf w^T\\mathbf x\n",
    "    $$\n",
    "  \n",
    "    - $y=\\mathbf w^T\\mathbf x=\\sum_iw_ix_i$\n",
    " \n",
    "\n",
    "$$\n",
    "\\frac{\\partial y}{\\partial \\mathbf x}=\\begin{bmatrix}w_1,w_2,\\cdots,w_n\\end{bmatrix}=\\mathbf w^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a02798-1f75-4ee3-b903-111096ce3d2a",
   "metadata": {},
   "source": [
    "## $\\alpha=\\mathbf y^T\\mathbf A\\mathbf x$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6a1cf2-9983-4956-a823-992475d7accf",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{split}\n",
    "&\\frac{\\partial \\alpha}{\\partial \\mathbf x}=\\mathbf y^T\\mathbf A\\\\\n",
    "&\\frac{\\partial \\alpha}{\\partial \\mathbf y}=\\mathbf x^T\\mathbf A^T\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "来看证明：\n",
    "- 对于第一个导数\n",
    "    - $\\mathbf w^T=\\mathbf y^T\\mathbf A$\n",
    "    - $\\alpha=\\mathbf w^T\\mathbf x$\n",
    "    - $\\frac{\\partial \\alpha}{\\partial \\mathbf x}=\\mathbf w^T=\\mathbf y^T\\mathbf A$\n",
    "- 对于第二个导数\n",
    "    - $\\alpha=\\alpha^T=\\mathbf x^T\\mathbf A^T\\mathbf y$\n",
    "    - $\\frac{\\partial \\alpha}{\\partial \\mathbf y}=\\mathbf x^T\\mathbf A^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4b4e24-a4c8-416e-bf9b-7fc884f1bcb0",
   "metadata": {},
   "source": [
    "## $\\alpha =\\mathbf x^T\\mathbf A\\mathbf x$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4c3f24-a6a4-4534-ab4c-f0163dbe2350",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial \\alpha}{\\partial \\mathbf x}=\\mathbf x^T(\\mathbf A+\\mathbf A^T)\n",
    "$$\n",
    "\n",
    "证明，基于矩阵矢量乘法的定义/计算：\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "&\\alpha=\\sum_ix_i\\sum_ja_{ij}x_j=\\sum_i\\sum_jx_ia_{ij}x_j\\\\\n",
    "&\\frac{\\partial \\alpha}{\\partial x_k}=\\sum_ix_ia_{ik}+\\sum_jx_ka_{kj}\\\\\n",
    "&\\frac{\\partial \\alpha}{\\partial \\mathbf x}=\\mathbf x^T\\mathbf A^T+\\mathbf x^T\\mathbf A=\\mathbf x^T(\\mathbf A+\\mathbf A^T)\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e3f441-f743-4960-9717-5787985c7219",
   "metadata": {},
   "source": [
    "## $\\mathbf y=\\mathbf A\\mathbf x$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac21bea0-bdab-4249-b874-1168678a34e6",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial \\mathbf y}{\\partial \\mathbf A}\n",
    "$$\n",
    "\n",
    "- 是一个三维的tensor\n",
    "    - $\\frac{\\partial y_i}{\\partial \\mathbf A}$ 各是一个矩阵\n",
    "    - $y_1=w_{11}x_1+w_{12}x_2$ => $\\begin{bmatrix}x_1 & x_2\\\\0 & 0\\end{bmatrix}$\n",
    "    - $y_2=w_{21}x_1+w_{22}x_2$ => $\\begin{bmatrix}0 & 0\\\\x_1 & x_2\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17d328b8-1ece-4f5c-ac2e-acbc2eea6e01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T15:56:20.864891Z",
     "iopub.status.busy": "2024-07-25T15:56:20.864573Z",
     "iopub.status.idle": "2024-07-25T15:56:20.876930Z",
     "shell.execute_reply": "2024-07-25T15:56:20.875451Z",
     "shell.execute_reply.started": "2024-07-25T15:56:20.864869Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 1.0000],\n",
       "        [0.5000, 1.0000],\n",
       "        [0.5000, 1.0000]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 定义矩阵 A 和向量 x\n",
    "A = torch.tensor([[1.0, 2.0],\n",
    "                  [3.0, 4.0],\n",
    "                  [5.0, 6.0]], requires_grad=True)\n",
    "\n",
    "x = torch.tensor([[0.5], [1.0]], requires_grad=True)\n",
    "\n",
    "# 计算 y = A * x\n",
    "y = torch.matmul(A, x)\n",
    "\n",
    "# 计算 y 对 A 的雅可比矩阵\n",
    "y.backward(torch.ones_like(y))\n",
    "\n",
    "# 获取雅可比矩阵\n",
    "jacobian = A.grad\n",
    "jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee1d2dde-253e-477a-aa48-606b68a0d6fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T16:01:02.084599Z",
     "iopub.status.busy": "2024-07-25T16:01:02.083954Z",
     "iopub.status.idle": "2024-07-25T16:01:02.104320Z",
     "shell.execute_reply": "2024-07-25T16:01:02.102808Z",
     "shell.execute_reply.started": "2024-07-25T16:01:02.084551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5000, 1.0000],\n",
       "         [0.0000, 0.0000],\n",
       "         [0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000],\n",
       "         [0.5000, 1.0000],\n",
       "         [0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000],\n",
       "         [0.0000, 0.0000],\n",
       "         [0.5000, 1.0000]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 定义矩阵 A 和向量 x\n",
    "A = torch.tensor([[1.0, 2.0],\n",
    "                  [3.0, 4.0],\n",
    "                  [5.0, 6.0]], requires_grad=True)\n",
    "\n",
    "x = torch.tensor([[0.5], [1.0]], requires_grad=True)\n",
    "\n",
    "# 计算 y = A * x\n",
    "y = torch.matmul(A, x)\n",
    "\n",
    "# 初始化一个与 A 形状相同的零张量来存储雅可比矩阵\n",
    "jacobian = torch.zeros((y.size(0), A.size(0), A.size(1)))\n",
    "\n",
    "# 逐元素计算雅可比矩阵\n",
    "for i in range(y.size(0)):\n",
    "    # 清除梯度\n",
    "    A.grad = None\n",
    "    \n",
    "    # 对 y 中的第 i 个元素进行反向传播\n",
    "    y[i].backward(retain_graph=True)\n",
    "    \n",
    "    # 将计算得到的梯度存储在雅可比矩阵中\n",
    "    jacobian[i] = A.grad\n",
    "jacobian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e810d22f-4c71-4c10-9086-a0286f859dbc",
   "metadata": {},
   "source": [
    "## loss backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23cf6f47-7610-480c-8493-fb78f7f8a88e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T15:39:50.734127Z",
     "iopub.status.busy": "2024-07-25T15:39:50.733453Z",
     "iopub.status.idle": "2024-07-25T15:39:51.997240Z",
     "shell.execute_reply": "2024-07-25T15:39:51.996772Z",
     "shell.execute_reply.started": "2024-07-25T15:39:50.734077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL/dx: tensor([[0.0000, 0.5000]])\n",
      "dL/dW: tensor([[1., 1.],\n",
      "        [2., 2.]])\n",
      "dL/db: tensor([[1., 1.]])\n",
      "Manual dL/dW: tensor([[1., 1.],\n",
      "        [2., 2.]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 设定输入 x 和权重 W，b 为偏置\n",
    "x = torch.tensor([[1.0, 2.0]], requires_grad=True)  # 1x2 行向量\n",
    "W = torch.tensor([[0.5, -0.5], [1.5, -1.0]], requires_grad=True)  # 2x2 矩阵\n",
    "b = torch.tensor([[0.1, -0.1]], requires_grad=True)  # 1x2 行向量\n",
    "\n",
    "# 前向传播计算 z = xW + b\n",
    "z = x @ W + b  # 矩阵乘法加上偏置\n",
    "\n",
    "# 定义一个简单的标量损失函数，假设为 z 的和\n",
    "L = z.sum()\n",
    "\n",
    "# 进行反向传播计算梯度\n",
    "L.backward()\n",
    "\n",
    "# 打印梯度\n",
    "print(\"dL/dx:\", x.grad)\n",
    "print(\"dL/dW:\", W.grad)\n",
    "print(\"dL/db:\", b.grad)\n",
    "\n",
    "# 手动验证梯度计算\n",
    "dL_dz = torch.ones_like(z)  # 因为 L = z.sum(), dL/dz = 1\n",
    "dz_dW = x.t()  # d(xW+b)/dW = x^T\n",
    "manual_dL_dW = dz_dW @ dL_dz  # outer product\n",
    "print(\"Manual dL/dW:\", manual_dL_dW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540acc3d-a2e2-4fd0-bf06-50024ca81d18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
