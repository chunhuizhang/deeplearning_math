{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcfe1eb3-4041-42f3-9de6-4fc3dfbaead1",
   "metadata": {},
   "source": [
    "- https://github.com/jbloomAus/SAELens/blob/main/tutorials/tutorial_2_0.ipynb\n",
    "- https://transformer-circuits.pub/2023/monosemantic-features\n",
    "    - https://transformer-circuits.pub/2023/monosemantic-features#setup-interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6885c4-2552-48e0-a1b8-2c4352c9ae09",
   "metadata": {},
   "source": [
    "- A basic introduction to SAEs.\n",
    "    - What is SAE Lens?\n",
    "    - Choosing an SAE to analyse and loading it with SAE Lens.\n",
    "    - The SAE Class and it's config.\n",
    "- SAE Features.\n",
    "    - What is a feature dashboard (仪表盘)?\n",
    "    - Loading feature dashboards on Neuronpedia.\n",
    "    - Downloading Autointerp and searching via explanations.\n",
    "- Feature inference\n",
    "    - Using the **HookedSAE** Transformer Class to **decompose activations into features**.\n",
    "    - Comparing Features accross related prompts.\n",
    "- Making Feature Dashboards\n",
    "    - Max Activating Examples\n",
    "    - Feature Activation Histograms\n",
    "    - Logit Weight Distributions.\n",
    "    - Extension: Reproducing `Not all language model features are linear`\n",
    "- SAE based Analysis Methods (Advanced)\n",
    "    - Steering model generation with SAE Features\n",
    "    - Ablating SAE Features\n",
    "    - Gradient-based Attribution for Circuit Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d851f60e-b5f3-4a34-947f-54131beb9b7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T14:16:38.563881Z",
     "iopub.status.busy": "2024-12-10T14:16:38.562551Z",
     "iopub.status.idle": "2024-12-10T14:16:40.655069Z",
     "shell.execute_reply": "2024-12-10T14:16:40.654092Z",
     "shell.execute_reply.started": "2024-12-10T14:16:38.563832Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "498aa872-7166-4828-a6f1-82e186addaeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T14:16:45.338845Z",
     "iopub.status.busy": "2024-12-10T14:16:45.338392Z",
     "iopub.status.idle": "2024-12-10T14:16:45.348581Z",
     "shell.execute_reply": "2024-12-10T14:16:45.347573Z",
     "shell.execute_reply.started": "2024-12-10T14:16:45.338811Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x79920efde410>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c643d0d2-1249-4721-aff7-02e23d0f214e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T14:16:51.774679Z",
     "iopub.status.busy": "2024-12-10T14:16:51.774275Z",
     "iopub.status.idle": "2024-12-10T14:16:51.789438Z",
     "shell.execute_reply": "2024-12-10T14:16:51.788252Z",
     "shell.execute_reply.started": "2024-12-10T14:16:51.774659Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8b5ddc-003e-4935-9f62-5c3ca56e50fd",
   "metadata": {},
   "source": [
    "### Loading a pretrained Sparse Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cc107b7-5b79-41a6-b82f-d83a9c9de176",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T14:17:09.837299Z",
     "iopub.status.busy": "2024-12-10T14:17:09.836028Z",
     "iopub.status.idle": "2024-12-10T14:17:13.496105Z",
     "shell.execute_reply": "2024-12-10T14:17:13.494329Z",
     "shell.execute_reply.started": "2024-12-10T14:17:09.837252Z"
    }
   },
   "outputs": [],
   "source": [
    "from sae_lens.toolkit.pretrained_saes_directory import get_pretrained_saes_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaed34a-2870-4a8b-ab29-aa943754eeab",
   "metadata": {},
   "source": [
    "- Joseph's Open Source GPT2 Small Residual (gpt2-small-res-jb)\n",
    "- Joseph's Feature Splitting (gpt2-small-res-jb-feature-splitting)\n",
    "- Gemma SAEs (gemma-2b-res-jb) (0,6) <- on Neuronpedia and good. (12 / 17 aren't very good currently)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "368acb2b-00c4-46f2-905a-1432240f5118",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T14:18:30.461922Z",
     "iopub.status.busy": "2024-12-10T14:18:30.460573Z",
     "iopub.status.idle": "2024-12-10T14:18:30.486938Z",
     "shell.execute_reply": "2024-12-10T14:18:30.485553Z",
     "shell.execute_reply.started": "2024-12-10T14:18:30.461875Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(\n",
    "    {k: v.__dict__ for k, v in get_pretrained_saes_directory().items()}\n",
    ").T\n",
    "df.drop(\n",
    "    columns=[\n",
    "        \"expected_var_explained\",\n",
    "        \"expected_l0\",\n",
    "        \"config_overrides\",\n",
    "        \"conversion_func\",\n",
    "    ],\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76ecefcf-a8a0-4349-9719-3aea75a278e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T14:18:32.135753Z",
     "iopub.status.busy": "2024-12-10T14:18:32.134975Z",
     "iopub.status.idle": "2024-12-10T14:18:32.171605Z",
     "shell.execute_reply": "2024-12-10T14:18:32.170233Z",
     "shell.execute_reply.started": "2024-12-10T14:18:32.135707Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>release</th>\n",
       "      <th>repo_id</th>\n",
       "      <th>model</th>\n",
       "      <th>saes_map</th>\n",
       "      <th>neuronpedia_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gemma-2b-it-res-jb</th>\n",
       "      <td>gemma-2b-it-res-jb</td>\n",
       "      <td>jbloom/Gemma-2b-IT-Residual-Stream-SAEs</td>\n",
       "      <td>gemma-2b-it</td>\n",
       "      <td>{'blocks.12.hook_resid_post': 'gemma_2b_it_blo...</td>\n",
       "      <td>{'blocks.12.hook_resid_post': 'gemma-2b-it/12-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-2b-res-jb</th>\n",
       "      <td>gemma-2b-res-jb</td>\n",
       "      <td>jbloom/Gemma-2b-Residual-Stream-SAEs</td>\n",
       "      <td>gemma-2b</td>\n",
       "      <td>{'blocks.0.hook_resid_post': 'gemma_2b_blocks....</td>\n",
       "      <td>{'blocks.0.hook_resid_post': 'gemma-2b/0-res-j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-scope-27b-pt-res</th>\n",
       "      <td>gemma-scope-27b-pt-res</td>\n",
       "      <td>google/gemma-scope-27b-pt-res</td>\n",
       "      <td>gemma-2-27b</td>\n",
       "      <td>{'layer_10/width_131k/average_l0_106': 'layer_...</td>\n",
       "      <td>{'layer_10/width_131k/average_l0_106': None, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-scope-27b-pt-res-canonical</th>\n",
       "      <td>gemma-scope-27b-pt-res-canonical</td>\n",
       "      <td>google/gemma-scope-27b-pt-res</td>\n",
       "      <td>gemma-2-27b</td>\n",
       "      <td>{'layer_10/width_131k/canonical': 'layer_10/wi...</td>\n",
       "      <td>{'layer_10/width_131k/canonical': 'gemma-2-27b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-scope-2b-pt-att</th>\n",
       "      <td>gemma-scope-2b-pt-att</td>\n",
       "      <td>google/gemma-scope-2b-pt-att</td>\n",
       "      <td>gemma-2-2b</td>\n",
       "      <td>{'layer_0/width_16k/average_l0_104': 'layer_0/...</td>\n",
       "      <td>{'layer_0/width_16k/average_l0_104': None, 'la...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           release  \\\n",
       "gemma-2b-it-res-jb                              gemma-2b-it-res-jb   \n",
       "gemma-2b-res-jb                                    gemma-2b-res-jb   \n",
       "gemma-scope-27b-pt-res                      gemma-scope-27b-pt-res   \n",
       "gemma-scope-27b-pt-res-canonical  gemma-scope-27b-pt-res-canonical   \n",
       "gemma-scope-2b-pt-att                        gemma-scope-2b-pt-att   \n",
       "\n",
       "                                                                  repo_id  \\\n",
       "gemma-2b-it-res-jb                jbloom/Gemma-2b-IT-Residual-Stream-SAEs   \n",
       "gemma-2b-res-jb                      jbloom/Gemma-2b-Residual-Stream-SAEs   \n",
       "gemma-scope-27b-pt-res                      google/gemma-scope-27b-pt-res   \n",
       "gemma-scope-27b-pt-res-canonical            google/gemma-scope-27b-pt-res   \n",
       "gemma-scope-2b-pt-att                        google/gemma-scope-2b-pt-att   \n",
       "\n",
       "                                        model  \\\n",
       "gemma-2b-it-res-jb                gemma-2b-it   \n",
       "gemma-2b-res-jb                      gemma-2b   \n",
       "gemma-scope-27b-pt-res            gemma-2-27b   \n",
       "gemma-scope-27b-pt-res-canonical  gemma-2-27b   \n",
       "gemma-scope-2b-pt-att              gemma-2-2b   \n",
       "\n",
       "                                                                           saes_map  \\\n",
       "gemma-2b-it-res-jb                {'blocks.12.hook_resid_post': 'gemma_2b_it_blo...   \n",
       "gemma-2b-res-jb                   {'blocks.0.hook_resid_post': 'gemma_2b_blocks....   \n",
       "gemma-scope-27b-pt-res            {'layer_10/width_131k/average_l0_106': 'layer_...   \n",
       "gemma-scope-27b-pt-res-canonical  {'layer_10/width_131k/canonical': 'layer_10/wi...   \n",
       "gemma-scope-2b-pt-att             {'layer_0/width_16k/average_l0_104': 'layer_0/...   \n",
       "\n",
       "                                                                     neuronpedia_id  \n",
       "gemma-2b-it-res-jb                {'blocks.12.hook_resid_post': 'gemma-2b-it/12-...  \n",
       "gemma-2b-res-jb                   {'blocks.0.hook_resid_post': 'gemma-2b/0-res-j...  \n",
       "gemma-scope-27b-pt-res            {'layer_10/width_131k/average_l0_106': None, '...  \n",
       "gemma-scope-27b-pt-res-canonical  {'layer_10/width_131k/canonical': 'gemma-2-27b...  \n",
       "gemma-scope-2b-pt-att             {'layer_0/width_16k/average_l0_104': None, 'la...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5e38c42-10c8-4c6d-9148-e81c9b27f222",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T14:23:54.727840Z",
     "iopub.status.busy": "2024-12-10T14:23:54.726469Z",
     "iopub.status.idle": "2024-12-10T14:23:54.744617Z",
     "shell.execute_reply": "2024-12-10T14:23:54.743228Z",
     "shell.execute_reply.started": "2024-12-10T14:23:54.727778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAEs in the GTP2 Small Resid Pre release\n",
      "SAE id: blocks.0.hook_resid_pre for hook point: blocks.0.hook_resid_pre\n",
      "SAE id: blocks.1.hook_resid_pre for hook point: blocks.1.hook_resid_pre\n",
      "SAE id: blocks.2.hook_resid_pre for hook point: blocks.2.hook_resid_pre\n",
      "SAE id: blocks.3.hook_resid_pre for hook point: blocks.3.hook_resid_pre\n",
      "SAE id: blocks.4.hook_resid_pre for hook point: blocks.4.hook_resid_pre\n",
      "SAE id: blocks.5.hook_resid_pre for hook point: blocks.5.hook_resid_pre\n",
      "SAE id: blocks.6.hook_resid_pre for hook point: blocks.6.hook_resid_pre\n",
      "SAE id: blocks.7.hook_resid_pre for hook point: blocks.7.hook_resid_pre\n",
      "SAE id: blocks.8.hook_resid_pre for hook point: blocks.8.hook_resid_pre\n",
      "SAE id: blocks.9.hook_resid_pre for hook point: blocks.9.hook_resid_pre\n",
      "SAE id: blocks.10.hook_resid_pre for hook point: blocks.10.hook_resid_pre\n",
      "SAE id: blocks.11.hook_resid_pre for hook point: blocks.11.hook_resid_pre\n",
      "SAE id: blocks.11.hook_resid_post for hook point: blocks.11.hook_resid_post\n",
      "--------------------------------------------------\n",
      "SAEs in the feature splitting release\n",
      "SAE id: blocks.8.hook_resid_pre_768 for hook point: blocks.8.hook_resid_pre_768\n",
      "SAE id: blocks.8.hook_resid_pre_1536 for hook point: blocks.8.hook_resid_pre_1536\n",
      "SAE id: blocks.8.hook_resid_pre_3072 for hook point: blocks.8.hook_resid_pre_3072\n",
      "SAE id: blocks.8.hook_resid_pre_6144 for hook point: blocks.8.hook_resid_pre_6144\n",
      "SAE id: blocks.8.hook_resid_pre_12288 for hook point: blocks.8.hook_resid_pre_12288\n",
      "SAE id: blocks.8.hook_resid_pre_24576 for hook point: blocks.8.hook_resid_pre_24576\n",
      "SAE id: blocks.8.hook_resid_pre_49152 for hook point: blocks.8.hook_resid_pre_49152\n",
      "SAE id: blocks.8.hook_resid_pre_98304 for hook point: blocks.8.hook_resid_pre_98304\n",
      "--------------------------------------------------\n",
      "SAEs in the Gemma base model release\n",
      "SAE id: blocks.0.hook_resid_post for hook point: gemma_2b_blocks.0.hook_resid_post_16384_anthropic\n",
      "SAE id: blocks.6.hook_resid_post for hook point: gemma_2b_blocks.6.hook_resid_post_16384_anthropic_fast_lr\n",
      "SAE id: blocks.10.hook_resid_post for hook point: gemma_2b_blocks.10.hook_resid_post_16384\n",
      "SAE id: blocks.12.hook_resid_post for hook point: gemma_2b_blocks.12.hook_resid_post_16384\n",
      "SAE id: blocks.17.hook_resid_post for hook point: gemma_2b_blocks.17.hook_resid_post_16384\n"
     ]
    }
   ],
   "source": [
    "print(\"SAEs in the GTP2 Small Resid Pre release\")\n",
    "for k, v in df.loc[df.release == \"gpt2-small-res-jb\", \"saes_map\"].values[0].items():\n",
    "    print(f\"SAE id: {k} for hook point: {v}\")\n",
    "print(\"-\" * 50)\n",
    "print(\"SAEs in the feature splitting release\")\n",
    "for k, v in (\n",
    "    df.loc[df.release == \"gpt2-small-res-jb-feature-splitting\", \"saes_map\"]\n",
    "    .values[0]\n",
    "    .items()\n",
    "):\n",
    "    print(f\"SAE id: {k} for hook point: {v}\")\n",
    "print(\"-\" * 50)\n",
    "print(\"SAEs in the Gemma base model release\")\n",
    "for k, v in df.loc[df.release == \"gemma-2b-res-jb\", \"saes_map\"].values[0].items():\n",
    "    print(f\"SAE id: {k} for hook point: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ed6d87d-d65a-47d7-b445-83fab771b6ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T14:22:35.088421Z",
     "iopub.status.busy": "2024-12-10T14:22:35.087079Z",
     "iopub.status.idle": "2024-12-10T14:22:35.095826Z",
     "shell.execute_reply": "2024-12-10T14:22:35.094475Z",
     "shell.execute_reply.started": "2024-12-10T14:22:35.088373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 768\n",
      "1 2 1536\n",
      "2 4 3072\n",
      "3 8 6144\n",
      "4 16 12288\n",
      "5 32 24576\n",
      "6 64 49152\n",
      "7 128 98304\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    print(i, 2**i, 2**i * 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb97d29d-8407-46ed-9c39-f4a5a6fd980f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T14:24:59.388154Z",
     "iopub.status.busy": "2024-12-10T14:24:59.386791Z",
     "iopub.status.idle": "2024-12-10T14:25:09.452534Z",
     "shell.execute_reply": "2024-12-10T14:25:09.451345Z",
     "shell.execute_reply.started": "2024-12-10T14:24:59.388104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7c6e0dfffb469f9082f227d41bf23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "blocks.7.hook_resid_pre/cfg.json:   0%|          | 0.00/1.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30fb249eea3f42acb76378cc68d25d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sae_weights.safetensors:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9e33cf74764ac699736cdfb1a0ead2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sparsity.safetensors:   0%|          | 0.00/98.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whaow/anaconda3/lib/python3.10/site-packages/sae_lens/sae.py:145: UserWarning: \n",
      "This SAE has non-empty model_from_pretrained_kwargs. \n",
      "For optimal performance, load the model like so:\n",
      "model = HookedSAETransformer.from_pretrained_no_processing(..., **cfg.model_from_pretrained_kwargs)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# from transformer_lens import HookedTransformer\n",
    "from sae_lens import SAE, HookedSAETransformer\n",
    "\n",
    "model = HookedSAETransformer.from_pretrained(\"gpt2-small\", device=device)\n",
    "\n",
    "# the cfg dict is returned alongside the SAE since it may contain useful information for analysing the SAE (eg: instantiating an activation store)\n",
    "# Note that this is not the same as the SAEs config dict, rather it is whatever was in the HF repo, from which we can extract the SAE config dict\n",
    "# We also return the feature sparsities which are stored in HF for convenience.\n",
    "sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
    "    release=\"gpt2-small-res-jb\",  # <- Release name\n",
    "    sae_id=\"blocks.7.hook_resid_pre\",  # <- SAE id (not always a hook point!)\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2e04a582-f59b-4b8e-86ef-c099afea4995",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T14:45:07.228575Z",
     "iopub.status.busy": "2024-12-10T14:45:07.228238Z",
     "iopub.status.idle": "2024-12-10T14:45:07.237562Z",
     "shell.execute_reply": "2024-12-10T14:45:07.236016Z",
     "shell.execute_reply.started": "2024-12-10T14:45:07.228554Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b6ee7980-f68e-4721-a465-e29d1fb7f407",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T14:31:34.838667Z",
     "iopub.status.busy": "2024-12-10T14:31:34.837308Z",
     "iopub.status.idle": "2024-12-10T14:31:34.845988Z",
     "shell.execute_reply": "2024-12-10T14:31:34.844034Z",
     "shell.execute_reply.started": "2024-12-10T14:31:34.838620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'architecture': 'standard', 'd_in': 768, 'd_sae': 24576, 'activation_fn_str': 'relu', 'apply_b_dec_to_input': True, 'finetuning_scaling_factor': False, 'context_size': 128, 'model_name': 'gpt2-small', 'hook_name': 'blocks.7.hook_resid_pre', 'hook_layer': 7, 'hook_head_index': None, 'prepend_bos': True, 'dataset_path': 'Skylion007/openwebtext', 'dataset_trust_remote_code': True, 'normalize_activations': 'none', 'dtype': 'torch.float32', 'device': 'cuda', 'sae_lens_training_version': None, 'activation_fn_kwargs': {}, 'neuronpedia_id': 'gpt2-small/7-res-jb', 'model_from_pretrained_kwargs': {'center_writing_weights': True}, 'seqpos_slice': (None,)}\n"
     ]
    }
   ],
   "source": [
    "print(sae.cfg.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cea22347-2d75-4285-b581-6d57d3b5e1b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T14:29:50.056660Z",
     "iopub.status.busy": "2024-12-10T14:29:50.055680Z",
     "iopub.status.idle": "2024-12-10T14:29:50.065039Z",
     "shell.execute_reply": "2024-12-10T14:29:50.063729Z",
     "shell.execute_reply.started": "2024-12-10T14:29:50.056614Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Skylion007/openwebtext', True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg_dict['dataset_path'], cfg_dict['prepend_bos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5fbf918c-daff-4622-932c-8abf6c9aa99e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T14:30:20.376279Z",
     "iopub.status.busy": "2024-12-10T14:30:20.374962Z",
     "iopub.status.idle": "2024-12-10T14:30:20.384707Z",
     "shell.execute_reply": "2024-12-10T14:30:20.383423Z",
     "shell.execute_reply.started": "2024-12-10T14:30:20.376229Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('none', 'torch.float32', 'cuda')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg_dict['normalize_activations'], cfg_dict['dtype'], cfg_dict['device']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d84dbed6-1b71-4bfa-a698-03d9dcf6d5ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T14:29:08.429078Z",
     "iopub.status.busy": "2024-12-10T14:29:08.427557Z",
     "iopub.status.idle": "2024-12-10T14:29:08.438972Z",
     "shell.execute_reply": "2024-12-10T14:29:08.437343Z",
     "shell.execute_reply.started": "2024-12-10T14:29:08.429023Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('blocks.7.hook_resid_pre', 7, None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg_dict['hook_point'], cfg_dict['hook_point_layer'], cfg_dict['hook_point_head_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e40b1935-8802-47ce-84db-d773593d6fd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T14:27:43.819546Z",
     "iopub.status.busy": "2024-12-10T14:27:43.818424Z",
     "iopub.status.idle": "2024-12-10T14:27:43.827076Z",
     "shell.execute_reply": "2024-12-10T14:27:43.825789Z",
     "shell.execute_reply.started": "2024-12-10T14:27:43.819498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'd_in': 768,\n",
    "# 'd_sae': 24576 (d_in * 32)\n",
    "# 'activation_fn_str': relu\n",
    "# apply_b_dec_to_input: dec_bias, true\n",
    "# 'context_size': 128\n",
    "24576 / 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb3dfe95-2d9e-40c9-bac5-318ebef9bd87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T14:32:16.009481Z",
     "iopub.status.busy": "2024-12-10T14:32:16.008177Z",
     "iopub.status.idle": "2024-12-10T14:32:36.647615Z",
     "shell.execute_reply": "2024-12-10T14:32:36.646837Z",
     "shell.execute_reply.started": "2024-12-10T14:32:16.009434Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "603202cbe7d64053bdd9cc68be1a9250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/373 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a5587516f674cc7a829599e6374b64e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dataset_infos.json:   0%|          | 0.00/921 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d35787b7c7b422581e639729455b3ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (229134 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformer_lens.utils import tokenize_and_concatenate\n",
    "\n",
    "dataset = load_dataset(\n",
    "    path=\"NeelNanda/pile-10k\",\n",
    "    split=\"train\",\n",
    "    streaming=False,\n",
    ")\n",
    "\n",
    "token_dataset = tokenize_and_concatenate(\n",
    "    dataset=dataset,  # type: ignore\n",
    "    tokenizer=model.tokenizer,  # type: ignore\n",
    "    streaming=True,\n",
    "    max_length=sae.cfg.context_size,\n",
    "    add_bos_token=sae.cfg.prepend_bos,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8b0d9ac9-e900-46d8-8a22-827b3ae80e97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T14:33:36.269452Z",
     "iopub.status.busy": "2024-12-10T14:33:36.268074Z",
     "iopub.status.idle": "2024-12-10T14:33:36.277568Z",
     "shell.execute_reply": "2024-12-10T14:33:36.276175Z",
     "shell.execute_reply.started": "2024-12-10T14:33:36.269406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is done, and submitted. You can play “Survival of the Tastiest” on Android, and on the web. Playi {'pile_set_name': 'Pile-CC'}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0]['text'][:100], dataset[0]['meta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5caa9ee6-12ad-4d73-892f-e69cb8fe9abf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T14:35:41.164446Z",
     "iopub.status.busy": "2024-12-10T14:35:41.163783Z",
     "iopub.status.idle": "2024-12-10T14:35:41.176723Z",
     "shell.execute_reply": "2024-12-10T14:35:41.174787Z",
     "shell.execute_reply.started": "2024-12-10T14:35:41.164402Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 128)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae.cfg.prepend_bos, sae.cfg.context_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "65b4c34f-5d35-4c24-942f-a6c1ef527bde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T14:35:11.115581Z",
     "iopub.status.busy": "2024-12-10T14:35:11.115319Z",
     "iopub.status.idle": "2024-12-10T14:35:11.121796Z",
     "shell.execute_reply": "2024-12-10T14:35:11.120846Z",
     "shell.execute_reply.started": "2024-12-10T14:35:11.115564Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50256]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tokenizer.encode('<|endoftext|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6c13503f-6c11-44c8-89d6-8b7c429dbc88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T14:35:32.436017Z",
     "iopub.status.busy": "2024-12-10T14:35:32.434649Z",
     "iopub.status.idle": "2024-12-10T14:35:32.445328Z",
     "shell.execute_reply": "2024-12-10T14:35:32.443883Z",
     "shell.execute_reply.started": "2024-12-10T14:35:32.435969Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_dataset[0]['tokens'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faefecf7-3725-474b-b950-3a40490e6aa2",
   "metadata": {},
   "source": [
    "### What are SAE Features?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eda74b8-d354-40af-9f21-8c6f8c977159",
   "metadata": {},
   "source": [
    "- An SAE feature represents **a pattern or concept** that the **autoencoder has learned to detect** in the input data. \n",
    "    - These features often correspond to **meaningful semantic, syntactic, or otherwise interpretable elements of text**, and correspond to **linear directions** in activation space.\n",
    "-  SAEs are trained on the **activations** of a specific part of the model, and after training, these features show up as **activations in the hidden layer** of the SAE (which is **much wider** than the source activation vector, and produces one hidden activation per feature).\n",
    "    -  As such, the hidden activations represent a decomposition of the entangled/superimposed features found in the original model activations.\n",
    "    -  Ideally, these activations are **sparse**: Only a few of the many possible hidden activations actually activate **for a given piece of input**. This sparseness tends to correspond to ease of interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "73f9010f-dfc5-4281-a078-4f42ae47ce6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T14:43:00.002886Z",
     "iopub.status.busy": "2024-12-10T14:43:00.001557Z",
     "iopub.status.idle": "2024-12-10T14:43:00.015152Z",
     "shell.execute_reply": "2024-12-10T14:43:00.013853Z",
     "shell.execute_reply.started": "2024-12-10T14:43:00.002831Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"600\"\n",
       "            src=\"https://neuronpedia.org/gpt2-small/7-res-jb/11943?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x79904fd3d6c0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "# get a random feature from the SAE\n",
    "feature_idx = torch.randint(0, sae.cfg.d_sae, (1,)).item()\n",
    "\n",
    "html_template = \"https://neuronpedia.org/{}/{}/{}?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
    "\n",
    "\n",
    "def get_dashboard_html(sae_release=\"gpt2-small\", sae_id=\"7-res-jb\", feature_idx=0):\n",
    "    return html_template.format(sae_release, sae_id, feature_idx)\n",
    "\n",
    "\n",
    "html = get_dashboard_html(\n",
    "    sae_release=\"gpt2-small\", sae_id=\"7-res-jb\", feature_idx=feature_idx\n",
    ")\n",
    "IFrame(html, width=1200, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dbdc07-1ad1-431f-96dd-06b22d66af40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
